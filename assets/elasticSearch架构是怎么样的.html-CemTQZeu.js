import{_ as e}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as o,a as n,o as a}from"./app-Ciq-_e96.js";const r={};function i(s,t){return a(),o("div",null,t[0]||(t[0]=[n(`<h1 id="elasticsearch-是什么-工作原理是怎么样的" tabindex="-1"><a class="header-anchor" href="#elasticsearch-是什么-工作原理是怎么样的"><span>elasticSearch 是什么？工作原理是怎么样的？</span></a></h1><p>现在有三段文本，id 分别是 0、1、2，你需要快速找到哪段文本里含有关键词&quot;xiaobai&quot;.</p><div class="language-c line-numbers-mode" data-ext="c" data-title="c"><pre class="language-c"><code>I like xiaobai        （点赞）
I follow xiaobai      （关注）
I forward the video   （转发）
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>我们很容易想到，可以依次遍历这三段文本，匹配文本内是否含有&quot;<strong>xiaobai</strong>&quot;，最终将符合条件的文本 ID 输出。<br> 在<strong>数据量小</strong>的时候，问题不大，但如果我有上百亿条这样的数据呢？<br> 如果依次遍历，这一把执行下去，比你喜欢的女生回你消息的速度，还要<strong>慢</strong>。<br> 像这种在海量数据中，通过关键词检索出有效信息的场景非常常见，比如我们网购用的某宝和某东的站内商品搜索。那么问题就来了，怎么处理类似的搜索场景呢？<br> 好办，<strong>没有什么是加一层中间层不能解决的，如果有，那就再加一层</strong>。<br> 这次我们要加的中间层是 <strong>elasticSearch</strong>。</p><figure><img src="https://cdn.xiaobaidebug.top/1719060283687.jpeg" alt="ES" tabindex="0" loading="lazy"><figcaption>ES</figcaption></figure><h2 id="什么是-elasticsearch。" tabindex="-1"><a class="header-anchor" href="#什么是-elasticsearch。"><span>什么是 elasticSearch。</span></a></h2><p>elastic Search, 也就是 es，是一个开源的搜索引擎。<br> 它介于<strong>应用</strong>和<strong>数据</strong>之间，只要将数据写入 es，应用就可以通过一些关键词搜索到数据。效果就像某度搜索一样。<br> 那它是怎么做到的呢？我们从倒排索引聊起。</p><h2 id="什么是倒排索引" tabindex="-1"><a class="header-anchor" href="#什么是倒排索引"><span>什么是倒排索引</span></a></h2><p>回到文章开头的例子。依次遍历文本匹配是否含有&quot;xiaobai&quot;，确实低效。那有更高效的解法吗？<br> 有，我们可以对文本进行切分，比如&quot;I like xiaobai&quot;切分为&quot;I&quot;、&quot;like&quot;、&quot;xiaobai&quot;三部分，这个操作叫<strong>分词</strong>，分词后的每部分，我们称为一个<strong>词项</strong>，也就是 <strong>term</strong>。记录词项和文本 id 的关系，于是上面的三段文本就变成了下面这样。</p><figure><img src="https://cdn.xiaobaidebug.top/1719060369630.jpeg" alt="词项是什么" tabindex="0" loading="lazy"><figcaption>词项是什么</figcaption></figure><table><thead><tr><th>term</th><th>文本 id</th></tr></thead><tbody><tr><td>I</td><td>0, 1, 2</td></tr><tr><td>like</td><td>0</td></tr><tr><td>xiaobai</td><td>0, 1</td></tr><tr><td>follow</td><td>1</td></tr><tr><td>forward</td><td>2</td></tr><tr><td>the</td><td>2</td></tr><tr><td>video</td><td>2</td></tr></tbody></table><p>当我们想要搜索 <code>xiaobai</code> 的时候，只需要匹配到 <code>xiaobai</code> 词项，就可以立马得到它所在的文档 id 是 0 和 1。<br> 但这有个问题，短短三句话，就已经有这么多词项了，要是换成三篇文档，那词项就会多得离谱，怎么在这么多的词项里匹配出 xiaobai 呢？挨个遍历的话，时间复杂度就是 <code>O(N)</code>, 太低效了。</p><p>怎么办呢？<br> 我们可以将词项<strong>按字典序</strong>从小到大排序，通过二分查找的方法，直接将时间复杂度优化为 <code>O(lgN)</code>。就像下面这样。</p><table><thead><tr><th>term</th><th>文档 id</th></tr></thead><tbody><tr><td>follow</td><td>1</td></tr><tr><td>forward</td><td>2</td></tr><tr><td>I</td><td>0, 1, 2</td></tr><tr><td>like</td><td>0</td></tr><tr><td>the</td><td>2</td></tr><tr><td>video</td><td>2</td></tr><tr><td>xiaobai</td><td>0, 1</td></tr></tbody></table><p>我们将这堆排好序的词项，称为<strong>Term Dictionary</strong>，而词项对应的文档 id 等信息的集合，就叫 <strong>Posting List</strong>。它们共同构成了一个用于搜索的数据结构，它就是<strong>倒排索引(Inverted Index)</strong>。</p><figure><img src="https://cdn.xiaobaidebug.top/1719060549588.jpeg" alt="倒排索引" tabindex="0" loading="lazy"><figcaption>倒排索引</figcaption></figure><blockquote><p>注意，Posting List 其实还包含<strong>词频</strong>和<strong>词项在文本里的偏移量</strong>等信息，但为了方便理解，我在上图中去掉了这部分内容。</p></blockquote><p>但倒排索引还有个问题，Term Dictionary 数据量很大，放<strong>内存</strong>并不现实，因此必须放在<strong>磁盘</strong>中。但查询磁盘是个较慢的过程。<br> 有优化手段吗？有，我们聊下 <strong>Term Index</strong>。</p><h2 id="term-index-是什么" tabindex="-1"><a class="header-anchor" href="#term-index-是什么"><span>Term Index 是什么</span></a></h2><p>我们可以发现，词项和词项之间，有些<strong>前缀</strong>是一致的，比如 <code>follow</code> 和 <code>forward</code> 前面的 <code>fo</code> 是一致的，如果我们将部分 term 前缀提取出来，像下图一样，就可以用更少的空间表达更多的 <strong>term</strong>。<br> 基于这个原理，我们可以将 Term Dictionary 的<strong>部分</strong>词项提取出来，用这些 词项 的前缀信息，构建出一个<strong>精简的目录树</strong>。目录树的节点中存放这些词项在磁盘中的偏移量，也就是指向磁盘中的位置。这个目录树结构，体积小，适合放内存中，它就是所谓的 <strong>Term Index</strong>。可以用它来加速搜索。</p><figure><img src="https://cdn.xiaobaidebug.top/1719060664024.jpeg" alt="Term Index是什么" tabindex="0" loading="lazy"><figcaption>Term Index是什么</figcaption></figure><p>当我们需要查找某个词项的时候，只需要搜索 Term Index，就能快速获得词项在 Term Dictionary 中的大概位置。再跳转到 Term Dictionary，通过少量的检索，定位到词项内容。</p><h2 id="stored-fields-是什么" tabindex="-1"><a class="header-anchor" href="#stored-fields-是什么"><span>Stored Fields 是什么</span></a></h2><p>到这里，搜索功能就有了。但有个问题，前面提到的倒排索引，搜索到的是<strong>文档 id</strong>，我们还需要拿着这个 id 找到<strong>文档内容本身</strong>，才能返回给用户。<br> 因此还需要有个地方，存放完整的文档内容，它就是 <strong>Stored Fields</strong>（行式存储）。</p><figure><img src="https://cdn.xiaobaidebug.top/1719060687244.jpeg" alt="Stored Fields" tabindex="0" loading="lazy"><figcaption>Stored Fields</figcaption></figure><h2 id="doc-values-是什么" tabindex="-1"><a class="header-anchor" href="#doc-values-是什么"><span>Doc Values 是什么</span></a></h2><p>有了 id，我们就能从 Stored Fields 中取出文档内容。</p><figure><img src="https://cdn.xiaobaidebug.top/1719060729127.jpeg" alt="Doc Values" tabindex="0" loading="lazy"><figcaption>Doc Values</figcaption></figure><p>但用户经常需要根据某个字段排序文档，比如按时间排序或商品价格排序。但问题就来了，这些字段散落在文档里。也就是说，我们需要先获取 Stored Fields 里的文档，再提取出内部字段进行排序。<br> 也不是说不行。但其实有更高效的做法。<br> 我们可以用<strong>空间换时间</strong>的思路，再构造一个<strong>列式存储</strong>结构，将散落在各个文档的某个字段，<strong>集中</strong>存放，当我们想对某个字段排序的时候，就只需要将这些集中存放的字段一次性读取出来，就能做到针对性地进行排序。这个列式存储结构，就是所谓的 <strong>Doc Values</strong>。</p><figure><img src="https://cdn.xiaobaidebug.top/1719060757527.jpeg" alt="Doc Values是什么" tabindex="0" loading="lazy"><figcaption>Doc Values是什么</figcaption></figure><h2 id="segment" tabindex="-1"><a class="header-anchor" href="#segment"><span>segment</span></a></h2><p>在上文中，我们介绍了四种关键的结构：<strong>倒排索引</strong>用于搜索，<strong>Term Index</strong> 用于加速搜索，<strong>Stored Fields</strong> 用于存放文档的原始信息，以及 <strong>Doc Values</strong> 用于排序和聚合。这些结构共同组成了一个<strong>复合</strong>文件，也就是所谓的&quot;<strong>segment</strong>&quot;, 它是一个具备<strong>完整搜索功能的最小单元</strong>。</p><figure><img src="https://cdn.xiaobaidebug.top/1719060773326.jpeg" alt="Segment是什么" tabindex="0" loading="lazy"><figcaption>Segment是什么</figcaption></figure><h2 id="lucene-是什么" tabindex="-1"><a class="header-anchor" href="#lucene-是什么"><span>lucene 是什么</span></a></h2><p>我们可以用多个文档生成一份 segment，<strong>如果</strong>新增文档时，还是写入到这份 segment，那就得同时更新 segment 内部的多个数据结构，这样并发读写时性能肯定会受影响。<br> 那怎么办呢？<br> 我们定个规矩。<strong>segment 一旦生成，则不能再被修改</strong>。如果还有新的文档要写入，那就生成新的 segment。<br> 这样<strong>老的 segment 只需要负责读，写则生成新的 segment</strong>。同时保证了读和写的性能。</p><p>但 segment 变多了，我们怎么知道要搜索的数据在哪个 segment 里呢？<br> 问题不大，<strong>并发同时读</strong>多个 segment 就好了。</p><figure><img src="https://cdn.xiaobaidebug.top/1719060793882.jpeg" alt="并发读" tabindex="0" loading="lazy"><figcaption>并发读</figcaption></figure><p>但这也引入了新问题，随着数据量增大，segment 文件越写越多，文件句柄被耗尽那是指日可待啊。<br> 是的，但这个也好解决，我们可以不定期合并多个小 segment，变成一个大 segment，也就是<strong>段合并</strong>(segment merging)。这样文件数量就可控了。</p><figure><img src="https://cdn.xiaobaidebug.top/1719060806214.jpeg" alt="段合并" tabindex="0" loading="lazy"><figcaption>段合并</figcaption></figure><p>到这里，上面提到的多个 segment，就共同构成了一个<strong>单机文本检索库</strong>，它其实就是非常有名的开源基础搜索库 <strong>lucene</strong>。<br> 不少知名搜索引擎都是基于它构建的，比如我们今天介绍的 ES。<br> 但这个 lucene 属实过于简陋，像什么高性能，高扩展性，高可用，它是一个都不沾。<br> 我们来看下怎么优化它。</p><h2 id="高性能" tabindex="-1"><a class="header-anchor" href="#高性能"><span>高性能</span></a></h2><p>lucene 作为一个搜索库，可以写入大量数据，并对外提供搜索能力。<br> 多个调用方<strong>同时读写</strong>同一个 lucene 必然导致争抢计算资源。抢不到资源的一方就得等待，这不纯纯浪费时间吗！<br> 有解决方案吗？有！<br> 首先是对写入 lucene 的数据进行分类，比如体育新闻和八卦新闻数据算两类，每一类是一个 <strong>Index Name</strong>，然后根据 Index Name 新增 lucene 的数量，将不同类数据写入到不同的 lucene 中，读取数据时，根据需要搜索不同的 Index Name 。这就大大降低了单个 lucene 的压力。</p><figure><img src="https://cdn.xiaobaidebug.top/1719060861197.jpeg" alt="index name是什么" tabindex="0" loading="lazy"><figcaption>index name是什么</figcaption></figure><p>但单个 Index Name 内数据依然可能过多，于是可以将单个 Index Name 的同类数据，拆成好几份，每份是一个 <strong>shard 分片</strong>，<strong>每个 shard 分片本质上就是一个独立的 lucene 库</strong>。<br> 这样我们就可以将读写操作分摊到多个 分片 中去，大大降低了争抢，提升了系统性能。</p><figure><img src="https://cdn.xiaobaidebug.top/1719060882499.jpeg" alt="Shard是什么" tabindex="0" loading="lazy"><figcaption>Shard是什么</figcaption></figure><h2 id="高扩展性" tabindex="-1"><a class="header-anchor" href="#高扩展性"><span>高扩展性</span></a></h2><p>随着 分片 变多，如果 分片 都在同一台机器上的话，就会导致单机 cpu 和内存过高，影响整体系统性能。</p><p>于是我们可以申请更多的机器，将 分片 <strong>分散</strong>部署在多台机器上，这每一台机器，就是一个 <strong>Node</strong>。我们可以通过增加 Node 缓解机器 cpu 过高带来的性能问题。</p><figure><img src="https://cdn.xiaobaidebug.top/1719060916626.jpeg" alt="高扩展性" tabindex="0" loading="lazy"><figcaption>高扩展性</figcaption></figure><h2 id="高可用" tabindex="-1"><a class="header-anchor" href="#高可用"><span>高可用</span></a></h2><p>到这里，问题又又来了，如果其中一个 Node 挂了，那 Node 里所有分片 都无法对外提供服务了。我们需要保证服务的高可用。有解决方案吗？<br> 有，我们可以给 分片 <strong>多加几个副本</strong>。将 分片 分为 <strong>Primary shard</strong> 和 <strong>Replica shard</strong>，也就是主分片和副本分片 。主分片会将数据同步给副本分片，副本分片<strong>既可以</strong>同时提供读操作，<strong>还能</strong>在主分片挂了的时候，升级成新的主分片让系统保持正常运行，<strong>提高性能</strong>的同时，还保证了系统的<strong>高可用</strong>。</p><figure><img src="https://cdn.xiaobaidebug.top/1719060935206.jpeg" alt="主分片和副本分片" tabindex="0" loading="lazy"><figcaption>主分片和副本分片</figcaption></figure><h2 id="node-角色分化" tabindex="-1"><a class="header-anchor" href="#node-角色分化"><span>Node 角色分化</span></a></h2><p>搜索架构需要支持的功能很多，既要负责<strong>管理集群</strong>，又要<strong>存储管理数据</strong>，还要<strong>处理客户端的搜索请求</strong>。如果每个 Node <strong>都</strong>支持这几类功能，那当集群有数据压力，需要扩容 Node 时，就会<strong>顺带</strong>把其他能力也一起扩容，但其实其他能力完全够用，不需要跟着扩容，这就有些<strong>浪费</strong>了。<br> 因此我们可以将这几类功能拆开，给集群里的 Node 赋予<strong>角色身份</strong>，不同的角色负责不同的功能。<br> 比如负责管理集群的，叫<strong>主节点(Master Node)</strong>， 负责存储管理数据的，叫<strong>数据节点(Data Node)</strong>， 负责接受客户端搜索查询请求的叫<strong>协调节点(Coordinate Node)</strong>。<br> 集群规模小的时候，一个 Node 可以<strong>同时</strong>充当多个角色，随着集群规模变大，可以让一个 Node 一个角色。</p><figure><img src="https://cdn.xiaobaidebug.top/1719060966460.jpeg" alt="角色分化" tabindex="0" loading="lazy"><figcaption>角色分化</figcaption></figure><h2 id="去中心化" tabindex="-1"><a class="header-anchor" href="#去中心化"><span>去中心化</span></a></h2><p>上面提到了主节点，那就意味着还有个<strong>选主</strong>的过程，但现在每个 Node 都是独立的，需要有个机制协调 Node 间的数据。<br> 我们很容易想到，可以像 <code>kafka</code> 那样引入一个中心节点 <code>Zookeeper</code>，但如果不想引入新节点，还有其他更轻量的方案吗？<br> 有，<strong>去中心化</strong>。<br> 我们可以在 Node 间引入协调模块，用<strong>类似一致性算法 Raft</strong> 的方式，在节点间互相同步数据，让所有 Node 看到的集群数据状态都是一致的。这样，集群内的 Node 就能参与选主过程，还能了解到集群内某个 Node 是不是挂了等信息。</p><figure><img src="https://cdn.xiaobaidebug.top/1719060976531.jpeg" alt="去中心化" tabindex="0" loading="lazy"><figcaption>去中心化</figcaption></figure><h2 id="es-是什么" tabindex="-1"><a class="header-anchor" href="#es-是什么"><span>ES 是什么？</span></a></h2><p>好了，到这里，当初那个简陋的 lucene，就成了一个高性能，高扩展性，高可用，支持持久化的分布式搜索引擎，它就是我们常说的 <strong>elastic search</strong>，简称 <strong>ES</strong>。它对外提供 <code>http</code> 接口，任何语言的客户端都可以通过 HTTP 接口接入 es，实现对数据的增删改查。<br> 从架构角度来看，es 给了一套方案，告诉我们如何让一个<strong>单机系统 lucene</strong> 变成一个<strong>分布式系统</strong>。</p><figure><img src="https://cdn.xiaobaidebug.top/1719060991824.jpeg" alt="ES是什么" tabindex="0" loading="lazy"><figcaption>ES是什么</figcaption></figure><p>按这个思路，是不是也可以将 lucene 改成其他单机系统，比如 <code>mysql</code> 数据库，或者专门做向量检索的单机引擎 <code>faiss</code>？<br> 那以后再来个 <code>elastic mysql</code> 或者 <code>elastic faiss</code> 是不是就不那么意外了，大厂内卷晋升或者下一个明星开源大项目的小提示就给到这里了。</p><p>看完 es 的架构，是不是觉得有些<strong>似曾相识</strong>？<br> 没错，我说的就是我前两期聊过的 <code>kafka</code>。</p><h2 id="es-和-kafka-的架构差异" tabindex="-1"><a class="header-anchor" href="#es-和-kafka-的架构差异"><span>ES 和 Kafka 的架构差异</span></a></h2><p>如果你不了解 kakfa 的架构，可以看下我之前写的《<strong>Kafka 是什么？</strong>》。<br> 然后你就会发现：</p><ul><li>es 中用于分类消息的 <code>Index Name</code>，其实就是 kafka 的 <code>topic</code>。</li><li>es 中用于对 Index Name 数据分片的 <code>Shard</code>，其实就是 kafka 中拆分 topic 数据的 <code>Partition</code>。</li><li>es 中用于分散部署多个 shard 的 <code>Node</code>, 其实就相当于 kafka 中的 <code>broker</code>。</li></ul><p>es 的架构跟 kafka 以及我们上期聊过的 rocketMQ 都非常相似，<strong>果然优秀的架构都是相似的，丑陋的架构各有各的丑陋</strong>。学一套优秀架构，就等于弄通了好几个中间件原理，简直血赚！</p><p>现在我们了解完 es 的架构，再来用两个实际例子将这些概念串起来，浅看下它的工作原理。</p><h2 id="es-的写入流程" tabindex="-1"><a class="header-anchor" href="#es-的写入流程"><span>ES 的写入流程</span></a></h2><ul><li>当<strong>客户端应用</strong>发起数据<strong>写入</strong>请求，请求会先发到集群中<strong>协调节点</strong>。</li><li>协调节点根据 hash 路由，判断数据该写入到哪个<strong>数据节点</strong>里的哪个<strong>分片</strong>(Shard)，找到<strong>主分片</strong>并写入。分片底层是 <strong>lucene</strong>，所以最终是将数据写入到 lucene 库里的 <strong>segment</strong> 内，将数据固化为<strong>倒排索引</strong>和 <strong>Stored Fields</strong> 以及 <strong>Doc Values</strong> 等多种结构。</li><li>主分片 写入成功后会将数据同步给 <strong>副本分片</strong>。</li><li>副本分片 写入完成后，<strong>主分片</strong>会响应协调节点一个 ACK，意思是写入完成。</li><li>最后，<strong>协调节点</strong>响应<strong>客户端应用</strong>写入完成。</li></ul><figure><img src="https://cdn.xiaobaidebug.top/1719061035966.jpeg" alt="写入流程" tabindex="0" loading="lazy"><figcaption>写入流程</figcaption></figure><h2 id="es-的搜索流程" tabindex="-1"><a class="header-anchor" href="#es-的搜索流程"><span>ES 的搜索流程</span></a></h2><p>ES 的搜索流程分为两个阶段：分别是<strong>查询阶段（Query Phase）<strong>和</strong>获取阶段（Fetch Phase）</strong><br> 我们分别看下。</p><figure><img src="https://cdn.xiaobaidebug.top/1719061047574.jpeg" alt="搜索两阶段" tabindex="0" loading="lazy"><figcaption>搜索两阶段</figcaption></figure><h3 id="查询阶段。" tabindex="-1"><a class="header-anchor" href="#查询阶段。"><span>查询阶段。</span></a></h3><ul><li>当<strong>客户端应用</strong>发起<strong>搜索</strong>请求，请求会先发到集群中的<strong>协调节点</strong>。</li><li>协调节点根据 <strong>index name</strong> 的信息，可以了解到 index name 被分为了几个 <strong>分片</strong>，以及这些分片 分散哪个<strong>数据节点</strong>上，将请求转发到这些数据节点的 分片 上面。</li><li>搜索请求到达分片后，分片 底层的 lucene 库会<strong>并发</strong>搜索多个 <strong>segment</strong>，利用每个 segment 内部的<strong>倒排索引</strong>获取到对应<strong>文档 id</strong>，并结合 <strong>doc values</strong> 获得<strong>排序信息</strong>。分片将结果聚合返回给<strong>协调节点</strong>。</li><li><strong>协调节点</strong>对多个分片中拿到的数据进行<strong>一次排序聚合</strong>，<strong>舍弃</strong>大部分不需要的数据。</li></ul><figure><img src="https://cdn.xiaobaidebug.top/1719061062084.jpeg" alt="查询阶段" tabindex="0" loading="lazy"><figcaption>查询阶段</figcaption></figure><h3 id="获取阶段。" tabindex="-1"><a class="header-anchor" href="#获取阶段。"><span>获取阶段。</span></a></h3><ul><li><strong>协调节点</strong>再次拿着<strong>文档 id</strong> 请求<strong>数据节点</strong>里的 <strong>分片</strong>，分片 底层的 lucene 库会从 segment 内的 <strong>Stored Fields</strong> 中取出<strong>完整文档内容</strong>，并返回给协调节点。</li><li><strong>协调节点</strong>最终将数据结果返回给<strong>客户端</strong>。完成整个搜索过程。</li></ul><figure><img src="https://cdn.xiaobaidebug.top/1719061075092.jpeg" alt="获取阶段" tabindex="0" loading="lazy"><figcaption>获取阶段</figcaption></figure><p>现在大家通了吗？</p><h2 id="总结" tabindex="-1"><a class="header-anchor" href="#总结"><span>总结</span></a></h2><ul><li>lucene 是 es 底层的单机文本检索库，它由多个 segment 组成，每个 segment 其实是由倒排索引、Term Index、Stored Fields 和 Doc Values 组成的具备完整搜索功能的最小单元。</li><li>将数据分类，存储在 es 内不同的 Index Name 中。</li><li>为了防止 Index Name 内数据过多，引入了 Shard 的概念对数据进行分片。提升了性能。</li><li>将多个 shard 分布在多个 Node 上，根据需要对 Node 进行扩容，提升扩展性。</li><li>将 shard 分为主分片和副本分片，主分片挂了之后由副本分片顶上，提升系统的可用性。</li><li>对 Node 进行角色分化，提高系统的性能和资源利用率，同时简化扩展和维护。</li><li>es 和 kafka 的架构非常像，可以类比学习。</li></ul>`,83)]))}const l=e(r,[["render",i],["__file","elasticSearch架构是怎么样的.html.vue"]]),c=JSON.parse('{"path":"/%E4%B8%AD%E9%97%B4%E4%BB%B6/es/%E6%A0%B8%E5%BF%83%E7%9F%A5%E8%AF%86%E7%82%B9/elasticSearch%E6%9E%B6%E6%9E%84%E6%98%AF%E6%80%8E%E4%B9%88%E6%A0%B7%E7%9A%84.html","title":"elasticSearch 是什么？工作原理是怎么样的？","lang":"zh-CN","frontmatter":{"description":"elasticSearch 是什么？工作原理是怎么样的？ 现在有三段文本，id 分别是 0、1、2，你需要快速找到哪段文本里含有关键词\\"xiaobai\\". 我们很容易想到，可以依次遍历这三段文本，匹配文本内是否含有\\"xiaobai\\"，最终将符合条件的文本 ID 输出。 在数据量小的时候，问题不大，但如果我有上百亿条这样的数据呢？ 如果依次遍历，这一把执...","head":[["meta",{"property":"og:url","content":"https://golangguide.top/%E4%B8%AD%E9%97%B4%E4%BB%B6/es/%E6%A0%B8%E5%BF%83%E7%9F%A5%E8%AF%86%E7%82%B9/elasticSearch%E6%9E%B6%E6%9E%84%E6%98%AF%E6%80%8E%E4%B9%88%E6%A0%B7%E7%9A%84.html"}],["meta",{"property":"og:site_name","content":"golang全栈指南"}],["meta",{"property":"og:title","content":"elasticSearch 是什么？工作原理是怎么样的？"}],["meta",{"property":"og:description","content":"elasticSearch 是什么？工作原理是怎么样的？ 现在有三段文本，id 分别是 0、1、2，你需要快速找到哪段文本里含有关键词\\"xiaobai\\". 我们很容易想到，可以依次遍历这三段文本，匹配文本内是否含有\\"xiaobai\\"，最终将符合条件的文本 ID 输出。 在数据量小的时候，问题不大，但如果我有上百亿条这样的数据呢？ 如果依次遍历，这一把执..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://cdn.xiaobaidebug.top/1719060283687.jpeg"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2024-06-23T02:15:26.000Z"}],["meta",{"name":"twitter:card","content":"summary_large_image"}],["meta",{"name":"twitter:image:alt","content":"elasticSearch 是什么？工作原理是怎么样的？"}],["meta",{"property":"article:author","content":"小白debug"}],["meta",{"property":"article:modified_time","content":"2024-06-23T02:15:26.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"elasticSearch 是什么？工作原理是怎么样的？\\",\\"image\\":[\\"https://cdn.xiaobaidebug.top/1719060283687.jpeg\\",\\"https://cdn.xiaobaidebug.top/1719060369630.jpeg\\",\\"https://cdn.xiaobaidebug.top/1719060549588.jpeg\\",\\"https://cdn.xiaobaidebug.top/1719060664024.jpeg\\",\\"https://cdn.xiaobaidebug.top/1719060687244.jpeg\\",\\"https://cdn.xiaobaidebug.top/1719060729127.jpeg\\",\\"https://cdn.xiaobaidebug.top/1719060757527.jpeg\\",\\"https://cdn.xiaobaidebug.top/1719060773326.jpeg\\",\\"https://cdn.xiaobaidebug.top/1719060793882.jpeg\\",\\"https://cdn.xiaobaidebug.top/1719060806214.jpeg\\",\\"https://cdn.xiaobaidebug.top/1719060861197.jpeg\\",\\"https://cdn.xiaobaidebug.top/1719060882499.jpeg\\",\\"https://cdn.xiaobaidebug.top/1719060916626.jpeg\\",\\"https://cdn.xiaobaidebug.top/1719060935206.jpeg\\",\\"https://cdn.xiaobaidebug.top/1719060966460.jpeg\\",\\"https://cdn.xiaobaidebug.top/1719060976531.jpeg\\",\\"https://cdn.xiaobaidebug.top/1719060991824.jpeg\\",\\"https://cdn.xiaobaidebug.top/1719061035966.jpeg\\",\\"https://cdn.xiaobaidebug.top/1719061047574.jpeg\\",\\"https://cdn.xiaobaidebug.top/1719061062084.jpeg\\",\\"https://cdn.xiaobaidebug.top/1719061075092.jpeg\\"],\\"dateModified\\":\\"2024-06-23T02:15:26.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"小白debug\\",\\"url\\":\\"https://xiaobaidebug.top/\\"}]}"],["link",{"rel":"canonical","href":"https://golangguide.top/%E4%B8%AD%E9%97%B4%E4%BB%B6/es/%E6%A0%B8%E5%BF%83%E7%9F%A5%E8%AF%86%E7%82%B9/elasticSearch%E6%9E%B6%E6%9E%84%E6%98%AF%E6%80%8E%E4%B9%88%E6%A0%B7%E7%9A%84.html"}],["meta",{"property":"og:url","content":"https://golangguide.top/%E4%B8%AD%E9%97%B4%E4%BB%B6/es/%E6%A0%B8%E5%BF%83%E7%9F%A5%E8%AF%86%E7%82%B9/elasticSearch%E6%9E%B6%E6%9E%84%E6%98%AF%E6%80%8E%E4%B9%88%E6%A0%B7%E7%9A%84.html"}],["meta",{"property":"og:site_name","content":"golang全栈指南"}],["meta",{"property":"og:title","content":"elasticSearch 是什么？工作原理是怎么样的？"}],["meta",{"property":"og:description","content":"elasticSearch 是什么？工作原理是怎么样的？ 现在有三段文本，id 分别是 0、1、2，你需要快速找到哪段文本里含有关键词\\"xiaobai\\". 我们很容易想到，可以依次遍历这三段文本，匹配文本内是否含有\\"xiaobai\\"，最终将符合条件的文本 ID 输出。 在数据量小的时候，问题不大，但如果我有上百亿条这样的数据呢？ 如果依次遍历，这一把执..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2024-06-23T02:15:26.000Z"}],["meta",{"property":"article:modified_time","content":"2024-06-23T02:15:26.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"elasticSearch 是什么？工作原理是怎么样的？\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2024-06-23T02:15:26.000Z\\",\\"author\\":[]}"]]},"headers":[{"level":2,"title":"什么是 elasticSearch。","slug":"什么是-elasticsearch。","link":"#什么是-elasticsearch。","children":[]},{"level":2,"title":"什么是倒排索引","slug":"什么是倒排索引","link":"#什么是倒排索引","children":[]},{"level":2,"title":"Term Index 是什么","slug":"term-index-是什么","link":"#term-index-是什么","children":[]},{"level":2,"title":"Stored Fields 是什么","slug":"stored-fields-是什么","link":"#stored-fields-是什么","children":[]},{"level":2,"title":"Doc Values 是什么","slug":"doc-values-是什么","link":"#doc-values-是什么","children":[]},{"level":2,"title":"segment","slug":"segment","link":"#segment","children":[]},{"level":2,"title":"lucene 是什么","slug":"lucene-是什么","link":"#lucene-是什么","children":[]},{"level":2,"title":"高性能","slug":"高性能","link":"#高性能","children":[]},{"level":2,"title":"高扩展性","slug":"高扩展性","link":"#高扩展性","children":[]},{"level":2,"title":"高可用","slug":"高可用","link":"#高可用","children":[]},{"level":2,"title":"Node 角色分化","slug":"node-角色分化","link":"#node-角色分化","children":[]},{"level":2,"title":"去中心化","slug":"去中心化","link":"#去中心化","children":[]},{"level":2,"title":"ES 是什么？","slug":"es-是什么","link":"#es-是什么","children":[]},{"level":2,"title":"ES 和 Kafka 的架构差异","slug":"es-和-kafka-的架构差异","link":"#es-和-kafka-的架构差异","children":[]},{"level":2,"title":"ES 的写入流程","slug":"es-的写入流程","link":"#es-的写入流程","children":[]},{"level":2,"title":"ES 的搜索流程","slug":"es-的搜索流程","link":"#es-的搜索流程","children":[{"level":3,"title":"查询阶段。","slug":"查询阶段。","link":"#查询阶段。","children":[]},{"level":3,"title":"获取阶段。","slug":"获取阶段。","link":"#获取阶段。","children":[]}]},{"level":2,"title":"总结","slug":"总结","link":"#总结","children":[]}],"git":{"createdTime":1719108926000,"updatedTime":1719108926000,"contributors":[{"name":"xiaobai-tech","email":"948485496@qq.com","commits":1}]},"readingTime":{"minutes":13.68,"words":4103},"filePathRelative":"中间件/es/核心知识点/elasticSearch架构是怎么样的.md","localizedDate":"2024年6月23日","autoDesc":true}');export{l as comp,c as data};
