import{_ as t,c as a,a as o,o as i}from"./app-YFeEz-zg.js";const n={};function g(p,e){return i(),a("div",null,e[0]||(e[0]=[o('<h1 id="海量数据怎么存-hdfs-是什么-架构是怎么样的" tabindex="-1"><a class="header-anchor" href="#海量数据怎么存-hdfs-是什么-架构是怎么样的"><span>海量数据怎么存？HDFS 是什么？架构是怎么样的？</span></a></h1><p>你是一个程序员，你太想进步了，于是准备下载 256g 的学习资料，放到电脑硬盘上。</p><p>但你的电脑最多只能存放 128g 数据。怎么办呢？</p><p>好办，你衣柜里还有台大学时的旧电脑。平分一下，正好够放。下岗机器再就业，你感觉你是个天才。</p><p>可麻绳总挑细处断，旧电脑磁盘终究还是写坏了。</p><p>于是你选择从衣柜里再拿两台旧电脑做备份。这样就不怕磁盘坏了。</p><p>但这个切分数据和备份数据的过程每次都得手动操作。</p><figure><img src="https://cdn.xiaobaidebug.top/1738382491158.jpeg" alt="手动切分和备份数据" tabindex="0" loading="lazy"><figcaption>手动切分和备份数据</figcaption></figure><p>不仅容易出错，还贼浪费时间！</p><p>有解法吗？</p><p>有，<strong>没有什么是加一层中间层不能解决的，如果有，那就再加一层</strong>。</p><p>这次我们要加的中间层是 <strong>HDFS</strong>。</p><figure><img src="https://cdn.xiaobaidebug.top/1738382516814.jpeg" alt="hdfs" tabindex="0" loading="lazy"><figcaption>hdfs</figcaption></figure><p>看之前，你点赞了吗？关注了吗？谢谢！</p><h2 id="hdfs-是什么" tabindex="-1"><a class="header-anchor" href="#hdfs-是什么"><span>HDFS 是什么？</span></a></h2><p>HDFS, 全名 Hadoop Distributed File System，是大数据领域常用的分布式文件系统。</p><p>你可以将它当做 <strong>应用服务</strong>和<strong>多个服务器文件系统</strong>的中间层，帮应用屏蔽掉背后的多个服务器，从多个服务器上读写文件数据，</p><p>并通过一系列策略保证数据可靠性，就算某些服务器磁盘坏了，也不影响数据完整。</p><figure><img src="https://cdn.xiaobaidebug.top/1738382550860.jpeg" alt="hdfs是应用服务和多个服务器文件系统的中间层" tabindex="0" loading="lazy"><figcaption>hdfs是应用服务和多个服务器文件系统的中间层</figcaption></figure><p>我们来看下它是怎么做到的。</p><h3 id="数据块是什么" tabindex="-1"><a class="header-anchor" href="#数据块是什么"><span>数据块是什么</span></a></h3><p>如果你有个超大文件，该怎么将它们存到多台服务器磁盘上呢？</p><p>按理说直接挑一台磁盘充足的服务器写入就好了，但如果每台服务器的剩余磁盘空间都不足以存下这个大文件呢？</p><p>好办, 我们可以<strong>将大文件切成多个数据块</strong>，也就是 <code>block</code>, 每个数据块默认 <code>128MB</code>。</p><figure><img src="https://cdn.xiaobaidebug.top/1738382581853.jpeg" alt="数据块" tabindex="0" loading="lazy"><figcaption>数据块</figcaption></figure><p>这个大小的数据块正好可以写入到多个服务器磁盘的<strong>犄角旮旯</strong>里，既完成了大文件的存储，又提升了<strong>磁盘空间利用率</strong>。</p><h2 id="容错" tabindex="-1"><a class="header-anchor" href="#容错"><span>容错</span></a></h2><p>但如果这时候某台服务器磁盘被写坏了，那背后牵连的很多大文件，就全废了。怎么办呢？</p><p>追爱路上遍体鳞伤的沸羊羊，会含泪给你答案，当然是多养几个<strong>备胎</strong>。</p><p>我们可以将数据块<strong>复制几份</strong>出来，<strong>分散放到不同服务器上</strong>，就算其中一台服务器跪了，还能从其他服务器上拿到数据块。分散了风险，大大提升了系统<strong>容错率</strong>！</p><figure><img src="https://cdn.xiaobaidebug.top/1738382598939.jpeg" alt="在其他服务器上冗余数据" tabindex="0" loading="lazy"><figcaption>在其他服务器上冗余数据</figcaption></figure><p>但问题又来了，大文件被拆成了多数据块，多副本写入后。如果程序想读大文件，<strong>怎么知道该从哪个服务器里读呢</strong>？</p><h2 id="hdfs-架构" tabindex="-1"><a class="header-anchor" href="#hdfs-架构"><span>HDFS 架构</span></a></h2><p>为了解决上面的问题，HDFS 会将我们的服务器集群划为<strong>两部分</strong>，一部分是<strong>Master 节点</strong>，也叫 NameNode，另一部分是<strong>Slave 节点</strong>，也叫<strong>DataNode</strong>。</p><figure><img src="https://cdn.xiaobaidebug.top/1738382626510.jpeg" alt="hdfs架构" tabindex="0" loading="lazy"><figcaption>hdfs架构</figcaption></figure><p>从名字能看出，它们的关系就是老板和打工人。</p><p><strong>NameNode</strong> 负责管理 DataNode，决定应用程序该到哪个 DataNode 去读写数据块。<strong>DataNode</strong> 才是真正负责存储数据块的牛马。</p><p>它们共同构成了 <strong>HDFS 集群</strong>，对外提供了读写文件，以及修改读写权限等一系列能力。</p><figure><img src="https://cdn.xiaobaidebug.top/1738382655583.jpeg" alt="hdfs集群" tabindex="0" loading="lazy"><figcaption>hdfs集群</figcaption></figure><p>而且 HDFS 还提供了 <strong>CLI</strong> 和 <strong>API</strong>，程序员可以方便地进行文件操作，<strong>不需要手写代码</strong>来处理大文件的拆分和组装。</p><figure><img src="https://cdn.xiaobaidebug.top/1738382666332.jpeg" alt="可以通过CLI和API访问hdfs" tabindex="0" loading="lazy"><figcaption>可以通过CLI和API访问hdfs</figcaption></figure><h2 id="datanode-是什么" tabindex="-1"><a class="header-anchor" href="#datanode-是什么"><span>DataNode 是什么</span></a></h2><p>牛马 <strong>DataNode</strong> 负责实际存储数据，很辛苦，但它的工作确实没什么技术含量，写坏了就用另外一块新的 DataNode 顶上。主打一个<strong>你不干，有的是 DataNode 愿意干</strong>。存储的数据量大了，就多加几个 DataNode。</p><p>正因为 DataNode 每天都需要疯狂读写，所以身体，啊不对，磁盘很容易垮，但是其他 DataNode 上面也备份了文件数据，可替代性很高，所以不用给它们配太好的服务器，能跑就行。</p><figure><img src="https://cdn.xiaobaidebug.top/1738382702840.jpeg" alt="datanode使用普通服务器" tabindex="0" loading="lazy"><figcaption>datanode使用普通服务器</figcaption></figure><p>反观 <strong>NameNode</strong>，就不一样了，它维护了<strong>所有服务器集群的信息</strong>，是大脑，是核心，金贵的很，所以得用高性能服务器好生供养着。</p><p>不行，越说越生气了。</p><figure><img src="https://cdn.xiaobaidebug.top/1738382722975.jpeg" alt="namenode使用高性能服务器" tabindex="0" loading="lazy"><figcaption>namenode使用高性能服务器</figcaption></figure><p>我们看下 NameNode 是怎么管理文件的？</p><h2 id="namenode-是什么" tabindex="-1"><a class="header-anchor" href="#namenode-是什么"><span>NameNode 是什么</span></a></h2><p>我们平时在电脑上，是通过<strong>目录树</strong>的形式管理文件。</p><p>而在 HDFS 的 NameNode 中，也用类似的目录树形式管理文件，每个文件都有对应文件名、大小和对应地址以及访问权限。这些信息，我们叫它<strong>元数据</strong>。</p><figure><img src="https://cdn.xiaobaidebug.top/1738382743025.jpeg" alt="元数据" tabindex="0" loading="lazy"><figcaption>元数据</figcaption></figure><p>这个管理目录树和元数据的能力，就叫 <strong>NameSpace</strong>。</p><p>同时 NameNode 还记录了某个文件，分成了多少个数据块这些信息。知道了大文件有哪些数据块后，我们还需要维护和管理数据块被存在了哪个 DataNode 上，这部分能力叫 <strong>Block Manager</strong>。</p><figure><img src="https://cdn.xiaobaidebug.top/1738382755479.jpeg" alt="NameNode内部" tabindex="0" loading="lazy"><figcaption>NameNode内部</figcaption></figure><h3 id="高性能" tabindex="-1"><a class="header-anchor" href="#高性能"><span>高性能</span></a></h3><p>为了支持高性能读写，NameNode 将 NameSpace 和 Block Manager 的数据<strong>全放内存</strong>中。</p><figure><img src="https://cdn.xiaobaidebug.top/1738382781087.jpeg" alt="NameNode将数据放内存" tabindex="0" loading="lazy"><figcaption>NameNode将数据放内存</figcaption></figure><h3 id="持久化" tabindex="-1"><a class="header-anchor" href="#持久化"><span>持久化</span></a></h3><p>但放内存里有个大问题，进程要是崩了，那数据就丢了。</p><p>怎么办呢?</p><p>我们可以将 NameSpace 和 Block Manager <strong>定期</strong>持久化到磁盘文件里，这个文件就是 <strong>fsimage</strong>，它记录了某一时刻 NameNode 的<strong>全量</strong>数据，类似于游戏的&quot;存档&quot;。</p><figure><img src="https://cdn.xiaobaidebug.top/1738382796979.jpeg" alt="NameNode数据存档" tabindex="0" loading="lazy"><figcaption>NameNode数据存档</figcaption></figure><p>但&quot;存档&quot;是需要时间的，在这次存档完成之后，下一次存档完成之前，写入的数据是不是会丢失呢？</p><p>好办，NameNode 会将&quot;存档&quot;后写入了哪些信息，记录到一个叫 <strong>editlog</strong> 的文件里，定时刷盘。这样就算进程挂了，重启的时候，通过加载 fsimage+editlog， 就能<strong>尽可能</strong>复原数据。保证了数据可靠性。</p><figure><img src="https://cdn.xiaobaidebug.top/1738382813819.jpeg" alt="引入editlog" tabindex="0" loading="lazy"><figcaption>引入editlog</figcaption></figure><h3 id="高可用" tabindex="-1"><a class="header-anchor" href="#高可用"><span>高可用</span></a></h3><p>想必大家也发现了，NameNode 是 HDFS 集群的核心，存在<strong>单点问题</strong>，要是崩了，那集群就没法对外提供服务了。</p><p>所以为了保证高可用，我们可以为 NameNode 配一个<strong>备用 NameNode， 也就是 Standby NameNode</strong>，平时主 NameNode 负责对外提供读写操作，备用 NameNode 只<strong>同步</strong> NameNode 的数据。</p><p>一旦 NameNode 挂了，备用 NameNode 就能立马<strong>顶上</strong>。保证了集群<strong>高可用</strong>。</p><figure><img src="https://cdn.xiaobaidebug.top/1738461877885.jpeg" alt="备用namenode" tabindex="0" loading="lazy"><figcaption>备用namenode</figcaption></figure><h2 id="可扩展" tabindex="-1"><a class="header-anchor" href="#可扩展"><span>可扩展</span></a></h2><p>但就算用了备用 NameNode，同一时刻，集群里其实<strong>只有一个</strong> NameNode 对外工作。</p><p>随着 HDFS 集群规模变大，NameNode 使用的内存也会变高。换句话说就是， HDFS 性能其实受限于<strong>单服务器节点的内存和 cpu 上限</strong>。那有办法扩展吗？</p><p>有！我们知道 NameNode 里的 NameSpace 本质上是个<strong>目录树</strong>。</p><figure><img src="https://cdn.xiaobaidebug.top/1738382863583.jpeg" alt="目录树" tabindex="0" loading="lazy"><figcaption>目录树</figcaption></figure><p>为了水平扩展，我们可以根据业务属性，<strong>对目录树进行拆分</strong>，也就是变成多个 NameSpace。</p><figure><img src="https://cdn.xiaobaidebug.top/1738382875919.jpeg" alt="根据业务拆分目录树" tabindex="0" loading="lazy"><figcaption>根据业务拆分目录树</figcaption></figure><p>再新增 NameNode，每个 NameNode 各自维护一个独立的 NameSpace，NameNode 之间完全不需要知道对方存了哪些数据，各自都只需要根据 DataNode 当前上报的磁盘信息就能完成读写操作。</p><p>通过这个方式，降低了 NameNode 单节点压力，同时提升了系统扩展性。这其实就是业界比较经典的 <strong>HDFS Federation</strong> 方案。</p><figure><img src="https://cdn.xiaobaidebug.top/1738382897463.jpeg" alt="HDFS Federation方案" tabindex="0" loading="lazy"><figcaption>HDFS Federation方案</figcaption></figure><p>但单个 NameSpace 还是有可能变得很大，怎么办呢？</p><p>好办，单个 NameSpace 过大并不合理，再拆小就行了。</p><p>这就很灵性了，<strong>在你质疑我扩展性有问题之前，我先反过来质疑你业务耦合过大</strong>，是不是能拆一下。在我解决架构问题之前，先解决掉提出问题的人，也不失为一种优雅的架构师思维。</p><p>接下来我们将上面提到的内容串起来。</p><h2 id="写大文件" tabindex="-1"><a class="header-anchor" href="#写大文件"><span>写大文件</span></a></h2><ul><li>客户端通过 HDFS API 向 <strong>NameNode</strong> 发送请求，准备写入文件。</li><li><strong>NameNode</strong> 在 <strong>NameSpace</strong> 中检查文件路径的合法性和客户端写权限，ok 的话，<strong>NameNode</strong> 会在 <strong>Edit Log</strong> 中记录新文件的元数据（比如文件路径、权限等），再更新 <strong>NameSpace</strong>。然后，<strong>NameNode</strong> 响应客户端。</li><li>之后客户端再请求 NameNode ，获取第一个数据块写入到哪些个 DataNode 上。</li></ul><figure><img src="https://cdn.xiaobaidebug.top/1738383013988.jpeg" alt="写入流程part1" tabindex="0" loading="lazy"><figcaption>写入流程part1</figcaption></figure><ul><li>NameNode 的<strong>Block Manager</strong> 会根据当前存储情况，告诉客户端数据块应该存储在哪些 <strong>DataNode</strong> 上。</li><li>客户端将数据块先写入主<strong>DataNode</strong>，DataNode 再将数据块副本同步写到其他 DataNode 上。</li><li>完成第一个数据块后。客户端通知 NameNode 数据块已成功写入。NameNode 更新数据块的时间戳，最终大小等。再写入 editlog。</li></ul><figure><img src="https://cdn.xiaobaidebug.top/1738383051317.jpeg" alt="写入流程part2" tabindex="0" loading="lazy"><figcaption>写入流程part2</figcaption></figure><ul><li>客户端再向 NameNode 获取第二个数据块该写到哪些个 NameNode 上，重复上面的操作，直到全部写完。</li><li><strong>DataNode</strong> 将数据块存储在本地文件系统后，会定期向 <strong>NameNode</strong> 汇报数据块状态。</li></ul><figure><img src="https://cdn.xiaobaidebug.top/1738383112750.jpeg" alt="datanode定期上报状态" tabindex="0" loading="lazy"><figcaption>datanode定期上报状态</figcaption></figure><ul><li><strong>NameNode</strong> 将文件的元数据变化记录到 NameSpace <strong>EditLog</strong> 中。并定期合并 <strong>EditLog</strong> 到 <strong>FsImage</strong>，以确保文件系统状态一致。</li><li><strong>备用 NameNode</strong> 会同步 <strong>EditLog</strong> 和 <strong>FsImage</strong>，以便在故障时可以接管。</li></ul><figure><img src="https://cdn.xiaobaidebug.top/1738383131383.jpeg" alt="备用namenode" tabindex="0" loading="lazy"><figcaption>备用namenode</figcaption></figure><p>通过上面步骤，HDFS 完成写入大文件。我们再来看下怎么将大文件读出来。</p><h2 id="读大文件" tabindex="-1"><a class="header-anchor" href="#读大文件"><span>读大文件</span></a></h2><ul><li>客户端向 NameNode 发送请求以获取目标文件的<strong>元数据</strong>信息。NameNode 返回文件的 block 列表及其对应的 DataNode 位置。</li><li>客户端根据 NameNode 返回的 DataNode 列表，选择一个合适的 DataNode ，建立 TCP 连接，并发送读取 block 的请求。</li><li>DataNode 收到请求后，将 block 数据发给客户端。客户端接收数据后，用 checksum 校验数据完整性。</li><li>重复以上步骤读取到多个数据块后，将多个数据块组装成大文件，完成读取。</li></ul><figure><img src="https://cdn.xiaobaidebug.top/1738383149455.jpeg" alt="读大文件" tabindex="0" loading="lazy"><figcaption>读大文件</figcaption></figure><p>现在大家通了吗？</p><h2 id="最后" tabindex="-1"><a class="header-anchor" href="#最后"><span>最后</span></a></h2><p>其实大部分后端开发平时不怎么使用 HDFS，但我却不得不聊下它，它是大数据体系的基石。基于 HDFS 的中间件有很多，比如 Hbase, Hive, Spark 等等，随便拉出一个来，都是王炸。就算不用，我们也可以学习下它们是怎么解决架构问题的。这在面试上拿出来吹牛，还不是嘎嘎乱杀？</p><h2 id="总结" tabindex="-1"><a class="header-anchor" href="#总结"><span>总结</span></a></h2><ul><li><p>你可以将 HDFS 当做 <strong>应用服务</strong>和<strong>多个服务器文件系统</strong>的中间层，帮应用屏蔽掉背后的多个服务器，从多个服务器上读写文件数据，</p></li><li><p>HDFS 会将文件分为多个数据块,并给数据块配备多个副本，有效利用磁盘空间的同时，还提升了数据可靠性。</p></li><li><p>HDFS 将集群分为 NameNode 和 DataNode 两部分，NameNode 负责管理文件元数据，DataNode 负责正在存储数据块。</p></li><li><p>NameNode 的内存中主要包含 NameSpace 和 block manager 两部分，NameSpace 负责管理目录树和元数据的组件。Block manager 维护和管理数据块被存在了哪个 DataNode 上。这些内存数据会刷入磁盘上的 fsimage 文件中形成快照，并通过 editlog 记录用户写操作，确保数据不丢</p></li><li><p>NameNode 将 NameSpace 和 block manager 加载到内存中，保证<strong>高性能</strong>。同时将内存数据会刷入磁盘上的 fsimage 文件中形成快照，并通过 editlog 记录用户写操作，确保数据<strong>持久化</strong>。为 NameNode 加入备用节点，保证高可用。通过 Federation 方案，提升了系统扩展能力。</p></li></ul>',104)]))}const r=t(n,[["render",g],["__file","hdfs是什么.html.vue"]]),s=JSON.parse('{"path":"/%E4%B8%AD%E9%97%B4%E4%BB%B6/hdfs/%E6%A0%B8%E5%BF%83%E7%9F%A5%E8%AF%86%E7%82%B9/hdfs%E6%98%AF%E4%BB%80%E4%B9%88.html","title":"海量数据怎么存？HDFS 是什么？架构是怎么样的？","lang":"zh-CN","frontmatter":{"description":"海量数据怎么存？HDFS 是什么？架构是怎么样的？ 你是一个程序员，你太想进步了，于是准备下载 256g 的学习资料，放到电脑硬盘上。 但你的电脑最多只能存放 128g 数据。怎么办呢？ 好办，你衣柜里还有台大学时的旧电脑。平分一下，正好够放。下岗机器再就业，你感觉你是个天才。 可麻绳总挑细处断，旧电脑磁盘终究还是写坏了。 于是你选择从衣柜里再拿两台旧...","head":[["meta",{"property":"og:url","content":"https://golangguide.top/%E4%B8%AD%E9%97%B4%E4%BB%B6/hdfs/%E6%A0%B8%E5%BF%83%E7%9F%A5%E8%AF%86%E7%82%B9/hdfs%E6%98%AF%E4%BB%80%E4%B9%88.html"}],["meta",{"property":"og:site_name","content":"golang全栈指南"}],["meta",{"property":"og:title","content":"海量数据怎么存？HDFS 是什么？架构是怎么样的？"}],["meta",{"property":"og:description","content":"海量数据怎么存？HDFS 是什么？架构是怎么样的？ 你是一个程序员，你太想进步了，于是准备下载 256g 的学习资料，放到电脑硬盘上。 但你的电脑最多只能存放 128g 数据。怎么办呢？ 好办，你衣柜里还有台大学时的旧电脑。平分一下，正好够放。下岗机器再就业，你感觉你是个天才。 可麻绳总挑细处断，旧电脑磁盘终究还是写坏了。 于是你选择从衣柜里再拿两台旧..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://cdn.xiaobaidebug.top/1738382491158.jpeg"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-02-02T02:14:51.000Z"}],["meta",{"name":"twitter:card","content":"summary_large_image"}],["meta",{"name":"twitter:image:alt","content":"海量数据怎么存？HDFS 是什么？架构是怎么样的？"}],["meta",{"property":"article:author","content":"小白debug"}],["meta",{"property":"article:modified_time","content":"2025-02-02T02:14:51.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"海量数据怎么存？HDFS 是什么？架构是怎么样的？\\",\\"image\\":[\\"https://cdn.xiaobaidebug.top/1738382491158.jpeg\\",\\"https://cdn.xiaobaidebug.top/1738382516814.jpeg\\",\\"https://cdn.xiaobaidebug.top/1738382550860.jpeg\\",\\"https://cdn.xiaobaidebug.top/1738382581853.jpeg\\",\\"https://cdn.xiaobaidebug.top/1738382598939.jpeg\\",\\"https://cdn.xiaobaidebug.top/1738382626510.jpeg\\",\\"https://cdn.xiaobaidebug.top/1738382655583.jpeg\\",\\"https://cdn.xiaobaidebug.top/1738382666332.jpeg\\",\\"https://cdn.xiaobaidebug.top/1738382702840.jpeg\\",\\"https://cdn.xiaobaidebug.top/1738382722975.jpeg\\",\\"https://cdn.xiaobaidebug.top/1738382743025.jpeg\\",\\"https://cdn.xiaobaidebug.top/1738382755479.jpeg\\",\\"https://cdn.xiaobaidebug.top/1738382781087.jpeg\\",\\"https://cdn.xiaobaidebug.top/1738382796979.jpeg\\",\\"https://cdn.xiaobaidebug.top/1738382813819.jpeg\\",\\"https://cdn.xiaobaidebug.top/1738461877885.jpeg\\",\\"https://cdn.xiaobaidebug.top/1738382863583.jpeg\\",\\"https://cdn.xiaobaidebug.top/1738382875919.jpeg\\",\\"https://cdn.xiaobaidebug.top/1738382897463.jpeg\\",\\"https://cdn.xiaobaidebug.top/1738383013988.jpeg\\",\\"https://cdn.xiaobaidebug.top/1738383051317.jpeg\\",\\"https://cdn.xiaobaidebug.top/1738383112750.jpeg\\",\\"https://cdn.xiaobaidebug.top/1738383131383.jpeg\\",\\"https://cdn.xiaobaidebug.top/1738383149455.jpeg\\"],\\"dateModified\\":\\"2025-02-02T02:14:51.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"小白debug\\",\\"url\\":\\"https://xiaobaidebug.top/\\"}]}"],["link",{"rel":"canonical","href":"https://golangguide.top/%E4%B8%AD%E9%97%B4%E4%BB%B6/hdfs/%E6%A0%B8%E5%BF%83%E7%9F%A5%E8%AF%86%E7%82%B9/hdfs%E6%98%AF%E4%BB%80%E4%B9%88.html"}],["meta",{"property":"og:url","content":"https://golangguide.top/%E4%B8%AD%E9%97%B4%E4%BB%B6/hdfs/%E6%A0%B8%E5%BF%83%E7%9F%A5%E8%AF%86%E7%82%B9/hdfs%E6%98%AF%E4%BB%80%E4%B9%88.html"}],["meta",{"property":"og:site_name","content":"golang全栈指南"}],["meta",{"property":"og:title","content":"海量数据怎么存？HDFS 是什么？架构是怎么样的？"}],["meta",{"property":"og:description","content":"海量数据怎么存？HDFS 是什么？架构是怎么样的？ 你是一个程序员，你太想进步了，于是准备下载 256g 的学习资料，放到电脑硬盘上。 但你的电脑最多只能存放 128g 数据。怎么办呢？ 好办，你衣柜里还有台大学时的旧电脑。平分一下，正好够放。下岗机器再就业，你感觉你是个天才。 可麻绳总挑细处断，旧电脑磁盘终究还是写坏了。 于是你选择从衣柜里再拿两台旧..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-02-02T02:14:51.000Z"}],["meta",{"property":"article:modified_time","content":"2025-02-02T02:14:51.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"海量数据怎么存？HDFS 是什么？架构是怎么样的？\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-02-02T02:14:51.000Z\\",\\"author\\":[]}"]]},"headers":[{"level":2,"title":"HDFS 是什么？","slug":"hdfs-是什么","link":"#hdfs-是什么","children":[{"level":3,"title":"数据块是什么","slug":"数据块是什么","link":"#数据块是什么","children":[]}]},{"level":2,"title":"容错","slug":"容错","link":"#容错","children":[]},{"level":2,"title":"HDFS 架构","slug":"hdfs-架构","link":"#hdfs-架构","children":[]},{"level":2,"title":"DataNode 是什么","slug":"datanode-是什么","link":"#datanode-是什么","children":[]},{"level":2,"title":"NameNode 是什么","slug":"namenode-是什么","link":"#namenode-是什么","children":[{"level":3,"title":"高性能","slug":"高性能","link":"#高性能","children":[]},{"level":3,"title":"持久化","slug":"持久化","link":"#持久化","children":[]},{"level":3,"title":"高可用","slug":"高可用","link":"#高可用","children":[]}]},{"level":2,"title":"可扩展","slug":"可扩展","link":"#可扩展","children":[]},{"level":2,"title":"写大文件","slug":"写大文件","link":"#写大文件","children":[]},{"level":2,"title":"读大文件","slug":"读大文件","link":"#读大文件","children":[]},{"level":2,"title":"最后","slug":"最后","link":"#最后","children":[]},{"level":2,"title":"总结","slug":"总结","link":"#总结","children":[]}],"git":{"createdTime":1738387734000,"updatedTime":1738462491000,"contributors":[{"name":"xiaobai-tech","email":"948485496@qq.com","commits":2}]},"readingTime":{"minutes":10.11,"words":3033},"filePathRelative":"中间件/hdfs/核心知识点/hdfs是什么.md","localizedDate":"2025年2月1日","autoDesc":true}');export{r as comp,s as data};
